\documentclass{article}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{amsthm}
% \smartqed  % flush right qed marks, e.g. at end of proof
% \usepackage{graphicx}
%\newtheorem{definition}[definition]{Definition}

% \pagenumbering{gobble}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{question}[theorem]{Question}
\newtheorem{example}[theorem]{Example}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
% \newtheorem{definition}[theorem]{Definition}
\newtheorem{principle}[theorem]{Principle}
\newtheorem{conjecture}[theorem]{Conjecture}

\begin{document}

\title{[Len's Proposed Abstract for a Nature Submission]Crowd-wisdom of universal reinforcement learning agents}
% \titlerunning{Agent mixtures and genericness}
\author{Samuel Allen Alexander \& Len Du \& Marcus Hutter}

% \institute{The U.S.\ Securities and Exchange Commission
% \email{samuelallenalexander@gmail.com}
% \url{https://philpeople.org/profiles/samuel-alexander/publications}}

\maketitle

\begin{abstract}
The wisdom, or intelligence, of a crowd, or of a collection of intelligent agents, has long been an attractive topic, with profound implications to a wide variety of disciplines, such as economics, political science, psychology, cognitive science, behavioral science, and many branches of social sciences.
Deep Reinforcement Learning, which has begun to experience a renaissance in recent years,
has great potential to help us understand the intelligence of crowds.

We introduce a theoretical model of intelligent crowds via
a weighted mixture operation which combines many reinforcement learning agents
into a single weighted mixture agent.
We formally prove a theoretical law governing the performance of the resulting
mixture agent, or crowd.
Namely: the weighted mixture agent's expected total reward
in any environment equals the corresponding weighted average
of the constituent agents' expected total rewards in that environment.
This law is also confirmed experimentally.
We hope our work will align reinforcement learning more closely
with conventional scientific paradigms, bringing together disparate
scientific communities and empowering each with theories and tools from
the others.
\end{abstract}

%\bibliographystyle{alpha}
%\bibliography{main}

\end{document}
