\documentclass{article}

\usepackage{AISTATS2023_Author_Response_Pack/aistats2023_author_response}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % define colors in text
\usepackage{xspace}         % fix spacing around commands

\begin{document}

This is the author response for ``Universal Agent Mixtures and the Geometry of Intelligence''
(submission 638).

\section{Reviewer 4 (``Accept'')}

Thank you for your insightful review. We particularly appreciate your note about the \emph{agent} vs.\ \emph{policy} terminology, and we will add some text to clarify.

\section{Reviewer 3 (``Accept'')}

Thank you for this detailed review. We particularly appreciate your suggestion to use Bayesian priors to further illuminate the main definition. Re: Proposition 39: thank you, you're right, in Definition 38 the "either...or" ought to be "both...and".

\section{Reviewers 2 (``Marginally below'') and 1 (``Reject'')}

Thank you for your constructive reviews. You make a great point that our introduction would
be improved by including language about the specific results that we later prove, as well as
about how these theoretical results are actually applicable. We intend to add such
language, which will greatly improve the paper. In particular, we will add language in
the introduction about applications:
\begin{itemize}
    \item
    By guaranteeing that ``the expected reward of a weighted mixture is the weighted
    average of the expected rewards,'' Theorem 14 offers an application to AI safety.
    Namely: it provides a way to mix reinforcement learning agents without the risk of
    unforeseen side-effects. For example, if several agents have different weaknesses,
    then, a priori, one might worry that when those agents are combined, those weaknesses
    might compound each other, leading to a combined weakness larger than the sum of the
    individual weaknesses; Theorem 14
    guarantees this does not occur with our agent mixtures.
    \item
    We already point out in Section 4 (Equivalence of Weak and Strong Symmetry)
    that the results there
    have implications for the search for inherently desirable properties of universal Turing
    machines. We will put this more front-and-center by adding language to that effect in the
    Introduction.
    \item
    Section 5 (Discernability and Separability) has applications for determining what
    sorts of things can or cannot be incentivized by reinforcement learning, in a formal sense 
    (analogous to how the Pumping Lemma can be used to show that, e.g., certain
    languages are not regular). Namely: if a set of agents does not satisfy the
    closure properties in this
    section, then it is hopeless to try to engineer an RL environment that ultimately rewards
    exactly that set of agents while punishing all other agents.
    \item
    Section 6 (Local Extrema and Lattice Points) has applications for the search for
    optimal reinforcement learning agents. It shows that the search space can be
    considerably narrowed down by restricting attention to deterministic agents. In concrete
    terms, the work here shows that nothing is gained by allowing agents to invoke
    genuine random number generators, e.g.\ expensive RNGs based on quantum mechanics etc.
\end{itemize}

\end{document}
