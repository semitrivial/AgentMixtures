\documentclass{article}

\usepackage{AISTATS2023_Author_Response_Pack/aistats2023_author_response}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % define colors in text
\usepackage{xspace}         % fix spacing around commands


\begin{document}

\section{Reviewer 4 (``Accept'')}

Thank you for your insightful review. We particularly appreciate your note about the \emph{agent} vs.\ \emph{policy} terminology, and we will add some text to clarify about that.

\section{Reviewer 3 (``Accept'')}

Thank you for this detailed review. We particularly appreciate your suggestion to use Bayesian priors to further illuminate the main definition.

\section{Reviewers 2 (``Marginally below'') and 1 (``Reject'')}

Thank you for your constructive reviews. You make a great point that our introduction would
be improved by including language about the specific results that we later prove, as well as
about how these theoretical results are actually applicable. Thanks
to you, we intend to add such language, which will greatly improve the paper. In particular,
we will add language in the introduction about applications:
\begin{itemize}
    \item
    We already point out in the weak and strong symmetry section that the results there
    have implications for the search for inherently desirable properties of universal Turing
    machines. We will put this more front-and-center by adding language to that effect in the
    Introduction as well.
    \item
    The discernability and separability section has applications toward determining what
    sorts of things can or cannot be incentivized by reinforcement learning. This is somewhat
    analogous to how the Pumping Lemma can be used to show that, e.g., certain languages are
    not regular. Namely: if a set of agents does not satisfy the closure properties in this
    section, then it is hopeless to try to engineer an RL environment that ultimately rewards
    exactly that set of agents while punishing its complement.
    \item
    The local extrema and lattice points section has applications for the search for
    optimal reinforcement learning agents. It shows that the search space can be very
    considerably narrowed down by restricting attention to deterministic agents. In concrete
    terms, the work here shows that nothing can be gained by allowing agents to invoke
    genuine random number generators, e.g.\ expensive RNGs based on quantum mechanics etc.
\end{itemize}

\end{document}
