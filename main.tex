%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%COLT header%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\documentclass[anon,12pt]{COLT2022/colt2022} % Anonymized submission
%\usepackage{times}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%AISTATS header%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[twoside]{article}
\usepackage{AISTATS2023PaperPack/aistats2023}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% not for COLT %%%%%%%%%%%%%%%
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{amsthm}
% \smartqed  % flush right qed marks, e.g. at end of proof
% \usepackage{graphicx}
%\newtheorem{definition}[definition]{Definition}
%
% \pagenumbering{gobble}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{example}[theorem]{Example}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
% \newtheorem{definition}[theorem]{Definition}
\newtheorem{conjecture}[theorem]{Conjecture}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newtheorem{principle}[theorem]{Principle}
\newtheorem{question}[theorem]{Question}

\begin{document}

\twocolumn[
%\aistatstitle{Instructions for Paper Submissions to AISTATS 2023}
%\aistatsauthor{ Author 1 \And Author 2 \And  Author 3 }
%\aistatsaddress{ Institution 1 \And  Institution 2 \And Institution 3 } ]

\aistatsauthor{Samuel Allen Alexander \& David Quarel \& Len Du \& Marcus Hutter}
\aistatstitle{Universal Agent Mixtures and the Geometry of Intelligence}

% \institute{The U.S.\ Securities and Exchange Commission
% \email{samuelallenalexander@gmail.com}
% \url{https://philpeople.org/profiles/samuel-alexander/publications}}

%\maketitle
]

%NOTE: " weighted linear " is kind of repetitive as linear implies weighted by default

\begin{abstract}
    Inspired by recent progress in multi-agent Reinforcement Learning (RL),
    in this work we examine the collective intelligent behaviour
    of theoretical universal agents by
    introducing a weighted mixture operation.
    Given a weighted set of agents,
    their weighted mixture is a new agent whose expected total reward in any environment
    is the corresponding weighted average
    of the original agents' expected total rewards in that environment.
    Thus, if RL agent intelligence is quantified in terms of performance across
    environments, the weighted mixture's intelligence is the weighted average of
    the original agents' intelligence.
    This operation enables
    various interesting new theorems that shed light on the geometry of RL
    agent intelligence, namely: results about symmetries, convex agent-sets,
    and local extrema. We also show that any RL agent intelligence measure
    based on average performance across environments, subject to certain
    weak technical conditions, is identical (up to a constant factor) to
    performance within a single environment dependent on said intelligence
    measure.
\end{abstract}

\section{Introduction}

Multi-agent reinforcement learning \cite{collective-1993,multiagent-1994-most-cited,multiagent-2021-most-cited}, as with other flavors of reinforcement learning, has been enjoying increased attention in artificial intelligence research \cite{unified-multiagent}.
Opinions about both further promises and challenges have emerged, particularly signified by the
high-profile attempt at replicating the super-human AI game-playing performance, in more complex realtime video games \cite{nature-starcraft},
than previous well-known AI game-playing achievements based on more vanilla deep reinforcement learning methods \cite{nature-ATARI,nature-go-2}.

The most obvious way to conceive multiagent reinforcement learning, is to passively consider the collective behavior of aggregated intelligent agents.
In fact, multiagent reinforcement learning had been first introduced as ``collective learning'' \cite{collective-1993} shortly before ever being explicitly called out as multiagent reinforcement learning \cite{multiagent-1994-most-cited}.


Not very surprisingly, collaboration of agents is a popular topic within multiagent reinforcement learning.
In fact, collaboration of artificial intelligence, or that between human and artificial intelligence, has attracted ample attention even without reinforcement learning.

One significant recent trend in machine learning (beyond just reinforcement learning) is federated learning \cite{federated-learning-2021}, which is mostly about programs physically running on disparate devices collaborating to form a more powerful artificial intelligence, and conceptually borrows from how humans collaborate.  Reinforcement had a much earlier head start with feudal reinforcement learning which incidentally borrowed the concept from more ancient human history.

As our result is derived from a very general and abstract definition of intelligence, it applies not only to collaboration among artificial intelligent agents, but also between human as intelligent agents and artificial ones.

In reinforcement learning (RL), an agent $\pi$ interacts with an environment $\mu$.
The agent and the environment take turns.
\begin{itemize}
\item
On $\pi$'s turn, $\pi$
outputs a probability distribution over a fixed action-set.
Based on this distribution, an action is sampled
and is transmitted to $\pi$ and $\mu$.
\item
On $\mu$'s turn, $\mu$
outputs a probability distribution over a fixed percept-set,
where every percept includes an observation (thought of as
the agent's view of the world) and a numerical reward.
Based on this distribution, a percept is sampled and
is transmitted to $\pi$ and $\mu$.
\end{itemize}
These turns continue forever, and the whole sequence of turns
is called an agent-environment interaction.

If $\pi_1$ and $\pi_2$ are two agents, we can informally imagine a new agent
$\sigma$
as follows. At the beginning of every agent-environment interaction,
$\sigma$ flips a fair coin. If the coin lands heads, then $\sigma$ transforms into
$\pi_1$; otherwise, $\sigma$ transforms into $\pi_2$. Note that the coin is only
flipped one time, at the very start of the agent-environment interaction:
it is not repeatedly flipped every turn. Intuitively, it seems like the
expected total reward in the agent-environment interaction
when $\sigma$ interacts with $\mu$, should be the average
of the corresponding expected total rewards when $\pi_1$ or $\pi_2$ interact
with $\mu$. But this is all quite informal, as the RL
framework does not actually provide any mechanism for such an initial
coin-flip.

More generally, given agents $\vec{\pi}=(\pi_1,\ldots,\pi_n)$ and positive real
numbers
$\vec{w}=(w_1,\ldots,w_n)$ with $w_1+\cdots+w_n=1$, we could imagine an agent $\sigma$
who, at the start of each agent-environment interaction, randomly chooses
an agent $\pi_i$ to act as (each candidate $\pi_i$ being chosen with probability
$w_i$). If each $\pi_i$ would get total expected reward $R_i$ from an environment
$\mu$, we would expect $\sigma$ should get total expected reward
$\vec{w}\cdot \vec{r}=w_1R_1+\cdots+w_nR_n$ from that environment.
But again, the RL
framework has no mechanism for such an agent $\sigma$. We will define
an agent $\vec{w}\cdot\vec{\pi}$, called a \emph{mixture agent},
within the constraints
of the RL framework, and prove that ``the expected total reward of the
weighted linear mixture is the linear combination of the expected total rewards''.
%We will then use this mixture operation to prove a number of interesting results.
This linearity result then leads to multiple further interesting results, of which the following we also discuss in this paper.
\begin{itemize}
    \item (((List the other results here)))
\end{itemize}

\section{Preliminaries}


Throughout the paper, we implicitly
fix non-empty finite sets $\mathcal A$ of \emph{actions},
$\mathcal O$ of \emph{observations},
and $\mathcal R\subseteq \mathbb Q\cap [-1,1]$ of \emph{rewards}.
By $\varepsilon$ we mean the empty sequence.
By $\mathcal E$ we mean $\mathcal O\times\mathcal R$ (the set of all observation-reward
pairs); elements of $\mathcal E$ are called \emph{percepts}.
By $\Delta\mathcal A$ (resp.\ $\Delta\mathcal E$) we mean the set of all $\mathbb Q$-valued
probability distributions on $\mathcal A$ (resp.\ on $\mathcal E$).

\begin{definition}
\label{omnibusdefn}
    (Agents, environments, etc.)
    \begin{enumerate}
        \item
        We denote the set of all finite sequences
        of alternating percept-action pairs $x_1y_1\ldots x_ty_t$
        by $(\mathcal E\mathcal A)^*$.
        We also include $\varepsilon$ in $(\mathcal E\mathcal A)^*$.
        Nonempty elements of $(\mathcal E\mathcal A)^*$ have the
        form $x_1y_1\ldots x_ty_t$ where each $x_i$ is a percept and
        each $y_i$ is an action.
        \item
        We denote the set of all sequences of the form $sx$ (where
        $s\in (\mathcal E\mathcal A)^*$, $x\in\mathcal E$, and $sx$
        is the result of appending $x$ to $s$) by
        $(\mathcal E\mathcal A)^*\mathcal E$.
        Elements of $(\mathcal E\mathcal A)^* \mathcal E$
        of length $>1$ have the form
        $x_1y_1\ldots x_{t-1}y_{t-1}x_t$
        (each $x_i$ a percept, each $y_i$ an action).
        \item
        An \emph{agent} is defined to be a function
        $\pi:(\mathcal E\mathcal A)^*\mathcal E\to \Delta \mathcal A$.
        For any $h\in (\mathcal E\mathcal A)^*\mathcal E$,
        we write $\pi(\cdot|h)$ for the value of $\pi$ at $h$, and
        for any $y\in \mathcal A$, we write $\pi(y|h)$ for
        $(\pi(\cdot|h))(y)$.
        Intuitively, $\pi(y|h)$ is the probability that agent $\pi$
        takes action $y$ in response to history $h$.
        \item
        An \emph{environment} is defined to be a function
        $\mu:(\mathcal E\mathcal A)^*\to\Delta\mathcal E$.
        For every $h\in(\mathcal E\mathcal A)^*$, we write
        $\mu(\cdot|h)$ for the value of $\mu$ at $h$, and for any
        $x\in\mathcal E$, we write $\mu(x|h)$ for $(\mu(\cdot|h))(x)$.
        If $x=(o,r)$ ($o\in\mathcal O$, $r\in\mathcal R$), we may also
        write $\mu(o,r|h)$ for $(\mu(\cdot|h))(x)$.
        Intuitively, $\mu(o,r|h)$ is the probability that environment
        $\mu$ issues percept $(o,r)$ (observation $o$ and reward $r$)
        to the agent in response to history $h$.
    \end{enumerate}
\end{definition}

\begin{remark}
\label{impossibleremark}
    Note that in Definition \ref{omnibusdefn} part 3, we require,
    e.g., $\pi(\cdot|x_1y_1x_2)$ to be defined even if
    $\pi(y_1|x_1)=0$, in which case the initial percept-action sequence $x_1y_1x_2$
    would have probability $0$ of ever occurring in any agent-environment
    interaction. Intuitively: an agent must choose actions even
    in response to histories that would never occur with nonzero probability.
    This convention (in which we follow \cite{legg2007universal}) simplifies
    many definitions.
\end{remark}

\begin{definition}
    By $\mathcal H$ we mean
    $((\mathcal E\mathcal A)^*)\cup((\mathcal E\mathcal A)^*\mathcal E)$,
    in other words, $\mathcal H$ is the set of alternating percept-action
    sequences that are empty or else start with a percept and can end with
    either a percept or an action.
    We refer to elements $h$ of $\mathcal H$ as \emph{histories} (a history
    may terminate with either a percept or an action).
\end{definition}

\begin{definition}
\label{pullbackdef}
    For all agents $\pi$, histories $h$, and environments $\mu$,
    we define real numbers $\Pi^\pi(h)$, $\Pi_\mu(h)$, and $\Pi^\pi_\mu(h)$
    inductively as follows.
    \begin{itemize}
        \item
        If $h=\varepsilon$ then $P^\pi(h)=P_\mu(h)=P^\pi_\mu(h)=1$.
        \item
        If $h=gx$ (some $x\in\mathcal E$) then
        $P^\pi(h)=P^\pi(g)$, $P_\mu(h)=P_\mu(g)\mu(x|g)$,
        and $P^\pi_\mu(h)=P^\pi_\mu(g)\mu(x|g)$.
        \item
        If $h=gy$ (some $y\in\mathcal A$) then
        $P^\pi(h)=P^\pi(g)\pi(y|g)$, $P_\mu(h)=P_\mu(g)$,
        and $P^\pi_\mu(h)=P^\pi_\mu(g)\pi(y|g)$.
    \end{itemize}
    Intuitively: $P^\pi(h)$ is the conditional
    probability $\pi$ will choose the actions in $h$ assuming the
    environment which $\pi$ is interacting with chooses the percepts in
    $h$; $P_\mu(h)$ is the conditional probability $\mu$ will choose
    the percepts in $h$ assuming the agent which $\mu$ is interacting
    with chooses the actions in $h$; and $P^\pi_\mu(h)$ is the probability
    that $\pi$ and $\mu$ will choose $h$'s actions and percepts when
    interacting together.
\end{definition}

Some authors, such as \cite{hutter2009discrete}, would write $P(h)$ or a variation thereof
for $P^\pi_\mu$, if $\pi$ and $\mu$ are clear from context.

One could alternately more directly define
\begin{align*}
    {} & P^\pi(x_1y_1\ldots x_ty_t)\\
    &= \pi(y_1|x_1)\pi(y_2|x_1y_1x_2)\cdots \pi(y_t|x_1y_1\ldots x_t),
\end{align*}
and similarly define $P^\pi(x_1y_1\ldots x_t)$,
and likewise for $P_\mu$ and for $P^\pi_\mu$.

\begin{lemma}
\label{factorizationlemma}
    For all $h$, $\pi$, $\mu$ as in Definition \ref{pullbackdef},
    \[
        P^\pi_\mu(h) = P^\pi(h)P_\mu(h).
    \]
\end{lemma}

\begin{proof}
    See Appendix.
\end{proof}

In the following definition (and the rest of the paper),
$\mathbb N$ denotes the set $\{0,1,2,\ldots\}$ of non-negative
integers.

\begin{definition}
\label{performancedefn}
    (Performance in an environment)
    Let $\pi$ be an agent, $\mu$ an environment.
    \begin{enumerate}
    \item
        For every $t\in\mathbb N$,
        we define
        \[
            V^\pi_{\mu,t}=\sum_{h\in X_t}R(h)P^\pi_\mu(h)
        \]
        where $X_t\subseteq\mathcal H$ is the set of all
        length-$2t$ histories (i.e., all $h\in\mathcal H$ of the form
        $x_1y_1\ldots x_ty_t$ (each $x_i\in\mathcal E$, each $y_i\in\mathcal A$)
        provided $t>0$) and $R(h)$ is the sum of the rewards in $h$.
        Intuitively, $V^\pi_{\mu,t}$ is the expected total reward
        if $\pi$ were to interact with $\mu$ for $t$ steps.
        Note that $X_0=\{\varepsilon\}$ and so $V^\pi_{\mu,0}=0$.
    \item
        We define $V^\pi_\mu=\lim_{t\to\infty}V^\pi_{\mu,t}$,
        provided the limit converges to a real number.
        Intuitively, $V^\pi_\mu$ is the expected total reward which $\pi$ would extract
        from $\mu$.
    \end{enumerate}
\end{definition}

Note that it is possible for $V^\pi_\mu$ to be undefined.
For example, if $\mu$ is an environment which always issues
reward $(-1)^t$ in response to the agent's $t$th action $y_t$,
then $V^\pi_\mu$ is undefined for every agent $\pi$.
But, following \cite{legg2007universal}, we will only be interested in
environments $\mu$ such that $V^\pi_\mu$
is always defined. Note also that, following \emph{ibid},
we delegate any possible reward discounting to the environments themselves,
rather than build a fixed reward discounting factor into the definition
of $V^\pi_\mu$.

\begin{definition}
\label{wellbehaveddefn}
    An environment $\mu$ is \emph{well-behaved} if $\mu$ is Turing
    computable and the following
    condition holds: for every agent $\pi$, $V^\pi_\mu$ exists and
    $-1\leq V^\pi_\mu\leq 1$. Let $W$ be the set of all well-behaved environments.
\end{definition}

\begin{definition}
\label{performanceaveragerdefn}
    By a \emph{weighted intelligence measure}, we mean a function
    $
        \Upsilon:
        (\Delta\mathcal A)^{(\mathcal E\mathcal A)^*\mathcal E}
        \to
        \mathbb R
    $
    (where
    $(\Delta\mathcal A)^{(\mathcal E\mathcal A)^*\mathcal E}$ denotes the set of all agents)
    such that there exist non-negative reals $\{w_\mu\}_{\mu\in W}$ such that the following
    condition holds:
    for every agent $\pi$, $\Upsilon(\pi)=\sum_{\mu\in W}w_\mu V^\pi_\mu$.
\end{definition}

The prototypical weighted intelligence measure is the Legg-Hutter intelligence
measure $\Upsilon$ introduced in \cite{legg2007universal},
where each well-behaved $\mu$ is
weighed using the universal prior \cite{li2008introduction}, i.e.,
given weight $2^{-K(\mu)}$
where $K$ denotes Kolmogorov complexity ($K(\mu)$ exists because of the Turing
computability requirement in Definition \ref{wellbehaveddefn}).
This depends on a background universal
Turing machine, the choice of which is highly nontrivial
\cite{leike2015bad}.

\section{Mixture agents}

Before defining mixture agents, we will first extend some of the above
definitions to vectors of agents.

\begin{definition}
\label{vectorizationdefn}
    Suppose $\vec\pi=(\pi_1,\ldots,\pi_n)$ is a vector of agents, $\mu$ is an environment,
    $h\in\mathcal H$, $t\in\mathbb N$, and $\Upsilon$ is a weighted
    intelligence measure. We define:
    \begin{itemize}
        \item ${P^{\vec\pi}}(h)=(P^{\pi_1}(h),\ldots,P^{\pi_n}(h))$.
        \item $P^{\vec\pi}_\mu(h)=(P^{\pi_1}_\mu(h),\ldots,P^{\pi_n}_\mu(h))$.
        \item $V^{\vec\pi}_{\mu,t}=(V^{\pi_1}_{\mu,t},\ldots,V^{\pi_n}_{\mu,t})$.
        \item $V^{\vec\pi}_\mu=(V^{\pi_1}_\mu,\ldots,V^{\pi_n}_\mu)$,
            if $V^{\pi_1}_\mu,\ldots,V^{\pi_n}_\mu$ are defined.
        \item $\Upsilon(\vec\pi)=(\Upsilon(\pi_1),\ldots,\Upsilon(\pi_n))$.
    \end{itemize}
\end{definition}

\begin{definition}
\label{dotproductdefn}
    If $\vec u=(u_1,\ldots,u_n)$ and
    $\vec v=(v_1,\ldots,v_n)$ are any two equal-length
    vectors of real numbers, then their \emph{dot product}
    is defined to be $\vec u\cdot \vec v=u_1v_1+\cdots+u_nv_n$.
\end{definition}

Now we are ready to define mixture agents.

\begin{definition}
\label{maindefn}
    (Mixture agents)
    Suppose $\vec\pi=(\pi_1,\ldots,\pi_n)$ are agents and $\vec w=(w_1,\ldots,w_n)$
    are positive real numbers with $w_1+\cdots+w_n=1$.
    Define the \emph{mixture agent} $\vec w\cdot\vec\pi$ as follows: for all
    $h\in (\mathcal E\mathcal A)^*\mathcal E$, $y\in\mathcal A$, let
    \[
        (\vec w\cdot\vec\pi)(y|h)
        =
        \begin{cases}
            \dfrac{\vec w\cdot {P^{\vec\pi}}(hy)}{\vec w\cdot {P^{\vec\pi}}(h)}
            &\mbox{if $\vec w\cdot {P^{\vec\pi}}(h)\not=0$,}\\
            1/|\mathcal{A}| &\mbox{otherwise.}
        \end{cases}
    \]
\end{definition}

\begin{remark}
    Definition \ref{maindefn} is complicated by the way
    Definition \ref{omnibusdefn} part 3
    forces us to include the case
    $(\vec w\cdot\vec\pi)(y|h)=1/|\mathcal A|$ when
    $\vec w\cdot {P^{\vec\pi}}(h)=0$
    (see Remark \ref{impossibleremark}): we are obligated to specify how
    $\vec w\cdot\vec\pi$ chooses actions even in response to ``impossible''
    histories for $\vec w\cdot\vec\pi$ (histories containing actions
    $\vec w\cdot\vec\pi$ would never take in those circumstances).
\end{remark}

\begin{lemma}
\label{mixturereallyisanagent}
    If $\vec\pi$ and $\vec w$ are as in Definition \ref{maindefn}
    then the mixture agent $\vec w\cdot\vec\pi$ is an agent
    (per Definition \ref{omnibusdefn} part 3).
\end{lemma}

\begin{proof}
    See Appendix.
\end{proof}

We will frequently use Lemma \ref{mixturereallyisanagent} without explicit mention.
For example, the lemma allows us to speak of $P^{\vec w\cdot \vec\pi}(h)$
(Definition \ref{pullbackdef}), $V^{\vec w\cdot\vec\pi}_{\mu}$
(Definition \ref{performancedefn}), etc., and we will freely do so without
explicitly citing Lemma \ref{mixturereallyisanagent}.

\begin{theorem}
\label{maintheorem}
    (Commutativity of $\vec w$)
    Let $\vec\pi=(\pi_1,\ldots,\pi_n)$ be agents.
    Let $\vec w=(w_1,\ldots,w_n)$ be positive reals with
    $w_1+\cdots+w_n=1$. Let $\mu$ be any environment.
    Then:
    \begin{enumerate}
        \item
        For any $h\in\mathcal H$,
        $P^{\vec w\cdot \vec\pi}(h)=\vec w\cdot {P^{\vec\pi}}(h)$.
        \item
        For any $h\in\mathcal H$,
        $P^{\vec w\cdot \vec\pi}_\mu(h)=\vec w \cdot P^{\vec\pi}_\mu(h)$.
        \item
        For any $t\in\mathbb N$,
        $V^{\vec w\cdot \vec\pi}_{\mu,t}=\vec w\cdot V^{\vec\pi}_{\mu,t}$.
        \item
        (``The expected reward of a weighted mixture is the weighted
        average of the expected rewards'')
        If $V^{\vec\pi}_\mu$ is defined, then
        $V^{\vec w\cdot\vec\pi}_\mu=\vec w\cdot V^{\vec\pi}_\mu$.
        \item
        (``The intelligence of a weighted mixture is the weighted average
        of the intelligences'')
        For any weighted intelligence measure $\Upsilon$,
        $\Upsilon(\vec w\cdot\vec\pi)=\vec w\cdot\Upsilon(\vec\pi)$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    (1) By induction on $h$.

    Case 1: $h=\varepsilon$. Then
    \[
        P^{\vec w\cdot\vec\pi}(h)=1=w_1\cdot 1+\cdots+w_n\cdot 1
        =
        \vec w\cdot ({P^{\vec\pi}}(h)).
    \]

    Case 2: $h=gx$ for some $x\in\mathcal E$. Then
    \begin{align*}
        P^{\vec w\cdot\vec\pi}(h)
            &= P^{\vec w\cdot\vec\pi}(g)
                &\mbox{(Definition \ref{pullbackdef})}\\
            &= \vec w\cdot({P^{\vec\pi}}(g))
                &\mbox{(Induction)}\\
            &= \vec w\cdot({P^{\vec\pi}}(gx))= \vec w\cdot({P^{\vec\pi}}(h)).
                &\mbox{(Definition \ref{pullbackdef})}
    \end{align*}

    Case 3: $h=gy$ for some $y\in\mathcal A$.

    Subcase 3.1: $P^{\vec w\cdot\vec\pi}(g)=0$.
        By induction $\vec w\cdot({P^{\vec\pi}}(g))=0$.
        Since the $w_i$ are positive, this implies
        each $P^{\pi_i}(g)=0$.
        Thus each
        \begin{align*}
            w_i P^{\pi_i}(gy)
                &= w_i P^{\pi_i}(g)\pi_i(y|g)
                    &\mbox{(Definition \ref{pullbackdef})}\\
                &= 0w_i\pi_i(y|g)=0,
        \end{align*}
        i.e., $\vec w\cdot({P^{\vec\pi}}(gy))=0$.
        And
        \begin{align*}
            P^{\vec w\cdot\vec\pi}(gy)
                &= P^{\vec w\cdot\vec\pi}(g)(\vec w\cdot\vec\pi)(y|g)
                    &\mbox{(Definition \ref{pullbackdef})}\\
                &= 0(\vec w\cdot\vec\pi)(y|g) = 0,
        \end{align*}
        so $P^{\vec w\cdot\vec\pi}(h)=\vec w\cdot P^{\vec\pi}(h)=0$.

    Subcase 3.2: ${P^{\vec w\cdot\vec\pi}}(g)\not=0$. Then
    \begin{align*}
        P^{\vec w\cdot\vec\pi}(h)
            &= P^{\vec w\cdot\vec\pi}(g)(\vec w\cdot\vec\pi)(y|g)
                &\mbox{(Definition \ref{pullbackdef})}\\
            &= P^{\vec w\cdot\vec\pi}(g)
                \frac
                {\vec w\cdot {P^{\vec\pi}}(gy)}
                {\vec w\cdot {P^{\vec\pi}}(g)}
                &\mbox{(Definition \ref{maindefn})}\\
            &= \vec w\cdot {P^{\vec\pi}}(g)
                \frac
                {\vec w\cdot {P^{\vec\pi}}(gy)}
                {\vec w\cdot {P^{\vec\pi}}(g)}
                &\mbox{(Induction)}\\
            &= \vec w\cdot {P^{\vec\pi}}(gy) = \vec w\cdot {P^{\vec\pi}}(h).
                &\mbox{(Basic Algebra)}
    \end{align*}

    (2) Follows from (1) and Lemma \ref{factorizationlemma}.

    (3) With $X_t$ and $R$ as in Definition \ref{performancedefn}, we compute:
    \begin{align*}
        V^{\vec w\cdot\vec\pi}_{\mu,t}
            &= \mbox{$\sum_{h\in X_t}R(h)P^{\vec w\cdot\vec\pi}_\mu(h)$}
                &\mbox{(Def.\ \ref{performancedefn})}\\
            &= \mbox{$\sum_{h\in X_t}\vec w\cdot R(h)P^{\vec\pi}_\mu(h)$}
                &\mbox{(By (2))}\\
            &= \mbox{$\vec w\cdot \sum_{h\in X_t}R(h)P^{\vec\pi}_\mu(h)$}
                &\mbox{(Vect.\ algebra)}\\
            &= \mbox{$
                \vec w\cdot
                \left(
                    \sum_{h\in X_t}R(h)P^{\pi_1}_\mu(h)
                \right)_{i=1}^n
                $}
                &\mbox{(Def.\ \ref{vectorizationdefn} part 2)}\\
            &= \vec w\cdot V^{\vec\pi}_{\mu,t}.
                &\mbox{(Def.\ \ref{vectorizationdefn} part 3)}
    \end{align*}

    (4) Follows from (3) and Definition \ref{performancedefn} part 2.

    (5) Follows from (4) and Definition \ref{performanceaveragerdefn}.
\end{proof}

\section{Equivalence of weak and strong symmetry}

In this section, we will investigate two symmetry properties
which a weighted intelligence measure might satisfy. A priori, one
property seems stricly stronger, but we will show
that in fact, they are equivalent. Throughout this section, we
assume that the background set $\mathcal R$ has the following
additional property:
whenever $\mathcal R$ contains any reward $r$, then $\mathcal R$
also contains $-r$.

\begin{definition}
\label{dualagentsdefn}
(Dual Agents and Dual Environments)
\begin{enumerate}
    \item
    For each $h\in\mathcal H$,
    we define the \emph{dual} of $h$, denoted $\overline h$, to be
    the sequence obtained
    by replacing every percept $(o,r)$ in $h$ by $(o,-r)$ (in other words:
    replacing every reward $r$ in $h$ by $-r$).
    \item
    Suppose $\pi$ is an agent.
    We define the \emph{dual} of $\pi$, denoted $\overline \pi$, as follows:
    for each $h\in (\mathcal E\mathcal A)^*\mathcal E$,
    for each action $y\in\mathcal A$,
    $\overline\pi(y|h)=\pi(y|\overline h)$.
\end{enumerate}
\end{definition}

\begin{lemma}
\label{doublenegationlemma}
    If $x$ is any agent or history,
    then
    $\overline{\overline x}=x$.
\end{lemma}

\begin{proof}
    Trivial as $-(-r)=r$ for all real $r$.
\end{proof}

\begin{lemma}
\label{asteriskcommuteswithoverlinelemma}
    For any agent $\pi$ and any $h\in(\mathcal E\mathcal A)^*\mathcal E$,
    $P^\pi(\overline h)=P^{\overline{\pi}}(h)$.
\end{lemma}

\begin{proof}
    By induction on $h$.
\end{proof}

\begin{definition}
    (Self-dual agents)
    An agent $\pi$ is \emph{self-dual} if $\overline{\pi}=\pi$.
\end{definition}

The main result in this section will be the equivalence of two
symmetry conditions on the intelligence of agents and their duals.
But first, we will use mixture agents to characterize
self-dual agents (up to equivalence modulo a natural equivalence relation).

\begin{definition}
\label{equivdefn}
    If $\pi$ and $\rho$ are agents, we say $\pi\equiv\rho$ if the
    following conditions hold:
    \begin{enumerate}
        \item For all $h\in\mathcal H$, $P^\pi(h)=0$ iff $P^\rho(h)=0$.
        \item For all $h\in(\mathcal E\mathcal A)^*\mathcal E$,
            if $P^\pi(h)\not=0$ then for all $y\in\mathcal A$,
            $\pi(y|h)=\rho(y|h)$.
    \end{enumerate}
\end{definition}

\begin{remark}
    Intuitively, Definition \ref{equivdefn} says that $\pi\equiv\rho$
    iff the histories which are ``possible'' for $\pi$ (in the sense of
    Remark \ref{impossibleremark}) are exactly the histories which are
    ``possible'' for $\rho$, and $\pi=\rho$ on those histories
    ($\pi$ and $\rho$ may differ on ``impossible'' histories).
\end{remark}

\begin{lemma}
\label{equivrelationlemma}
    $\equiv$ (Definition \ref{equivdefn}) is an equivalence
    relation.
\end{lemma}

\begin{proof}
    Straightforward.
\end{proof}

\begin{lemma}
\label{piopluspilemma}
    Let $\vec w=(w_1,\ldots,w_n)$ be positive reals,
    $w_1+\cdots+w_n=1$. For every agent $\pi$,
    $\pi\equiv\vec w\cdot (\pi,\ldots,\pi)$ (where
    $(\pi,\ldots,\pi)$ has length $n$).
\end{lemma}

\begin{proof}
    See Appendix.
\end{proof}

\begin{lemma}
\label{reflectionmakesjanuslemma}
    For any agent $\pi$,
    $(\frac12,\frac12)\cdot(\pi,\overline\pi)$ is self-dual.
\end{lemma}

\begin{proof}
    See Appendix.
\end{proof}

\begin{proposition}
\label{janusagentcharacterizationproposition}
    (Characterization of self-dual agents modulo $\equiv$)
    For any agent $\pi$, the following are equivalent:
    \begin{enumerate}
        \item $\pi\equiv\rho$ for some self-dual agent $\rho$.
        \item $\pi\equiv(\frac12,\frac12)\cdot(\rho,\overline{\rho})$
            for some agent $\rho$.
    \end{enumerate}
\end{proposition}

\begin{proof}
    ($\Rightarrow$)
    Assume $\pi\equiv\rho$ for some self-dual agent $\rho$.
    By Lemma \ref{piopluspilemma}
    $\rho\equiv (\frac12,\frac12)\cdot(\rho,\rho)$,
    but $\rho=\overline{\rho}$ by self-duality,
    so
    $\rho\equiv (\frac12,\frac12)\cdot(\rho,\overline{\rho})$.
    By transitivity of $\equiv$ (Lemma \ref{equivrelationlemma}),
    $\pi\equiv(\frac12,\frac12)\cdot(\rho,\overline{\rho})$.

    ($\Leftarrow$)
    Assume $\pi\equiv(\frac12,\frac12)\cdot(\rho,\overline{\rho})$ for some agent $\rho$.
    By Lemma \ref{reflectionmakesjanuslemma},
    $(\frac12,\frac12)\cdot(\rho,\overline{\rho})$ is self-dual.
\end{proof}

Proposition \ref{janusagentcharacterizationproposition} is analogous to the
fact that a function $f:\mathbb R\to\mathbb R$ is even
(i.e.\ satisfies $f(x)=f(-x)$)
iff $f(x)=\frac12(g(x)+g(-x))$ for some $g:\mathbb R\to\mathbb R$.

We will show in Corollary \ref{equivalentsymmetriescor} that
the following two symmetry conditions are equivalent.

\begin{definition}
    (Weighted intelligence measure symmetry properties)
    Let $\Upsilon$ be a weighted intelligence measure.
    \begin{enumerate}
        \item $\Upsilon$ is \emph{weakly symmetric} if
            $\Upsilon(\pi)=0$ for every self-dual agent $\pi$.
        \item $\Upsilon$ is \emph{strongly symmetric} if
            $\Upsilon(\overline\pi)=-\Upsilon(\pi)$ for every agent $\pi$.
    \end{enumerate}
\end{definition}

\begin{theorem}
\label{equivalentsymmetriescor}
    A weighted intelligence measure $\Upsilon$ is weakly
    symmetric iff it is strongly symmetric.
\end{theorem}

\begin{proof}
    (Weak $\Rightarrow$ Strong)
    Assume $\Upsilon$ is weakly symmetric.
    Let $\pi$ be any agent.
    By Lemma \ref{reflectionmakesjanuslemma},
    $(\frac12,\frac12)\cdot(\pi,\overline\pi)$ is self-dual.
    So by weak symmetry,
    $\Upsilon((\frac12,\frac12)\cdot(\pi,\overline\pi))=0$.
    Thus by Theorem \ref{maintheorem} (part 5),
    \[
        (\mbox{$\frac12$},\mbox{$\frac12$})\cdot\Upsilon((\pi,\overline\pi))
        =\mbox{$\frac12$}\Upsilon(\pi)+\mbox{$\frac12$}\Upsilon(\overline\pi)=0.
    \]
    So $\Upsilon(\overline{\pi})=-\Upsilon(\pi)$.
    By arbitrariness of $\pi$, $\Upsilon$ is strongly symmetric.

    (Strong $\Rightarrow$ Weak)
    Trivial.
\end{proof}

The canonical weighted intelligence measure is the universal
intelligence measure $\Upsilon_U$ of \cite{legg2007universal},
where each computable environment
$\mu$ is given weight $2^{-K(\mu)}$, where $K(\mu)$ is $\mu$'s Kolmogorov complexity.
This depends non-trivially on the background UTM $U$,
prompting Leike and Hutter to ask: ``What are [...] desirable
properties of a UTM?'' \cite{leike2015bad}.
UTMs formalize programming languages, so the question is equivalent
to ``What are desirable properties of a programming language?'' (i.e., \emph{inherently}
desirable properties, as opposed to subjectively desirable properties like whether or
not white-space matters).
Intrinsically desirable UTM properties are elusive; attempts
(like \cite{muller2010stationary}) to find them confirm the difficulty thereof.
In the RL context, symmetry conditions on $\Upsilon_U$ are candidate desirable properties
for the UTM: $U$ is weakly (resp.\ strongly) symmetric iff $\Upsilon_U$ is.
The equivalence of weak and strong symmetry provides some justification for
considering this UTM property to be inherently desirable (in the RL context).


\section{Discernability and separability}

In this section, we give another application of mixture agents.
We define natural notions of \emph{discernability} and \emph{separability}
for sets of agents,
and we give an interesting characterization of separability
in terms of discernability and mixtures.
Below, if $\Pi$ is a set of agents, then
$\Pi^c$ is the set of agents $\rho$ such that $\rho\not\in\Pi$.

\begin{definition}
\label{discernabilitydefn}
    A set $\Pi$ of agents is \emph{discernable} if there exists
    an environment $\mu$ such that for all agents $\pi$, $\rho$:
    \begin{enumerate}
        \item $V^\pi_\mu$ exists.
        \item If $\pi\in\Pi$ and $\rho\in\Pi^c$, then $V^\pi_\mu\not=V^\rho_\mu$.
    \end{enumerate}
\end{definition}

Intuitively, $\Pi$ is discernable if there is some environment in which
no member of $\Pi$ has the same expected performance as any member of $\Pi^c$.

For the next definition, recall that a subset $I$ of the reals
is \emph{convex} if the following requirement holds:
for all real $i_1<i_2<i_3$, if $i_1\in I$ and $i_3\in I$, then $i_2\in I$.
Two sets are \emph{disjoint} if they have no point in common.

\begin{definition}
\label{incentivizabilitydefn}
    A set $\Pi$ of agents is \emph{separable} if there exists
    an environment $\mu$ and disjoint convex sets $I$ and $J$ of
    the reals such that for every agent $\pi$:
    \begin{enumerate}
        \item
        $V^\pi_\mu$ exists.
        \item
        If $\pi\in \Pi$ then $V^\pi_\mu\in I$.
        \item
        If $\pi\in \Pi^c$ then $V^\pi_\mu\in J$.
    \end{enumerate}
\end{definition}

Intuitively, $\Pi$ is separable if there is some environment in which
the performance measures of members of $\Pi$ are separated into one
convex set, and the performance measures of outsides of $\Pi$ are separated
into a different convex set, with no overlap.
Clearly separability implies discernability, but what about the converse?
We will state a partial converse making use of mixtures.

\begin{definition}
\label{mixtureclosuredef}
    A set $\Pi$ is \emph{closed under mixtures} if the following
    holds: for all $\vec w=(w_1,\ldots,w_n)$
    with $w_1+\cdots+w_n=1$,
    for all agents $\vec\pi=(\pi_1,\ldots,\pi_n)$,
    if $\pi_i\in \Pi$ for every $i=1,\ldots,n$, then
    $\vec w\cdot\vec\pi\in\Pi$.
\end{definition}

\begin{lemma}
\label{ivtlemma}
    For any real numbers $A\leq B\leq C$, there exists some real $0\leq \alpha\leq 1$
    such that $\alpha A + (1-\alpha)C=B$.
\end{lemma}

\begin{proof}
    Let $\alpha=(C-B)/(C-A)$ (or $\alpha=1$ if $A=C$).
\end{proof}

\begin{theorem}
    (Characterization of Separability)
    For any set $\Pi$ of agents, the following are equivalent:
    \begin{enumerate}
        \item $\Pi$ is separable.
        \item $\Pi$ is discernable, and both $\Pi$ and $\Pi^c$ are closed under mixtures.
    \end{enumerate}
\end{theorem}

\begin{proof}
    ($1\Rightarrow 2$)
    Assume $\Pi$ is separable, and let $\mu,I,J$ be as in
    Definition \ref{incentivizabilitydefn}, so $I$ and $J$ are disjoint.

    To see $\Pi$ is discernable, let $\pi,\rho$ be any agents.
    By condition 1 of Definition \ref{incentivizabilitydefn},
    $V^\pi_\mu$ exists. And if $\pi\in\Pi$, $\rho\in\Pi^c$, then
    by conditions 2 and 3 of Definition \ref{incentivizabilitydefn},
    $\pi\in I$ and $\rho\in J$. Since $I$ and $J$ are disjoint,
    $V^\pi_\mu\not=V^\rho_\mu$. This shows $\Pi$ is discernable.

    To see $\Pi$ is closed under mixtures, let $\vec w=(w_1,\ldots,w_n)$
    and $\vec\pi=(\pi_1,\ldots,\pi_n)$ be as in Definition \ref{mixtureclosuredef}
    and assume each $\pi_i\in\Pi$.
    By choice of $I$, each $V^{\pi_i}_\mu\in I$.
    By Theorem \ref{maintheorem},
    $V^{\vec w\cdot\vec\pi}_\mu=\vec w\cdot V^{\vec\pi}_\mu$.
    Thus $V^{\vec w\cdot\vec\pi}_\mu$ is a convex combination
    of $V^{\pi_1}_\mu,\ldots,V^{\pi_n}_\mu$, which are elements of $I$.
    Since $I$ is convex, it follows that $V^{\vec w\cdot\vec\pi}_\mu\in I$.
    Since $I$ and $J$ are disjoint, $V^{\vec w\cdot\vec\pi}_\mu\not\in J$,
    so by choice of $J$, $\vec w\cdot\vec\pi\in\Pi$, as desired.
    A similar argument shows $\Pi^c$ is closed under mixtures.

    ($2\Rightarrow 1$)
    Assume $\Pi$ is discernable and both $\Pi$ and $\Pi^c$ are closed under mixtures.
    Since $\Pi$ is discernable, there is some environment $\mu$
    as in Definition \ref{discernabilitydefn}.
    Define
    \begin{align*}
        I &= \{
            r\in\mathbb R
            \,:\,
            \exists \pi_1,\pi_2\in\Pi\mbox{ s.t. }V^{\pi_1}_\mu\leq r\leq V^{\pi_2}_\mu
        \},\\
        J &= \{
            r\in\mathbb R
            \,:\,
            \exists \rho_1,\rho_2\in\Pi^c\mbox{ s.t. }V^{\rho_1}_\mu\leq r\leq V^{\rho_2}_\mu
        \}.
    \end{align*}

    Claim 1: $I$ is convex. To see this, let $i_1<i_2<i_3$ be any reals
    such that $i_1\in I$ and $i_3\in I$.
    By definition of $I$, there are $\pi_1,\pi_2\in\Pi$
    such that $V^{\pi_1}_\mu\leq i_1\leq V^{\pi_2}_\mu$,
    and there are $\pi'_1,\pi'_2\in\Pi$ such that
    $V^{\pi'_1}_\mu\leq i_3\leq V^{\pi'_2}_\mu$.
    It follows that $V^{\pi_1}_\mu\leq i_2\leq V^{\pi'_2}_\mu$,
    which shows $i_2\in I$, as desired.

    Claim 2: $J$ is convex. Similar to Claim 1.

    Claim 3: $I$ and $J$ are disjoint. Assume not. Then there is some $r\in I\cap J$.
    By definition of $I$, there are $\pi_1,\pi_2\in\Pi$ such that
    $V^{\pi_1}_\mu\leq r\leq V^{\pi_2}_\mu$, and by definition of $J$,
    there are $\rho_1,\rho_2\in\Pi^c$ such that $V^{\rho_1}_\mu\leq r\leq V^{\rho_2}_\mu$.
    By Lemma \ref{ivtlemma}, there is some real $\alpha\in [0,1]$
    such that $\alpha V^{\pi_1}_\mu + (1-\alpha)V^{\pi_2}_\mu=r$.
    Let $\pi=(\alpha,1-\alpha)\cdot (\pi_1,\pi_2)$.
    By Theorem \ref{maintheorem} (part 4),
    $V^\pi_\mu = \alpha V^{\pi_1}_\mu + (1-\alpha)V^{\pi_2}_\mu=r$.
    And since $\Pi$ is closed under mixtures, $\pi\in\Pi$.
    By identical reasoning using $V^{\rho_1}_\mu\leq r\leq V^{\rho_2}_\mu$,
    there exists some $\rho\in \Pi^c$ such that $V^\rho_\mu=r$.
    But since $\mu$ satisfies condition 2 of
    Definition \ref{discernabilitydefn}, 
    and $\pi\in\Pi$ and $\rho\in\Pi^c$, this forces
    $V^\pi_\mu\not=V^\rho_\mu$, absurd.

    Claim 4: For all $\pi\in \Pi$, $V^\pi_\mu\in I$, and for all $\rho\in\Pi^c$,
    $V^\rho_\mu\in J$. This is immediate from the definition of $I$ and $J$,
    using $\pi_1=\pi=\pi_2$ and $\rho_1=\rho=\rho_2$.

    By Claims 1--4, $\mu,I,J$ witness that $\Pi$ is separable.
\end{proof}

\section{Local extrema and lattice points of intelligence surfaces}

\begin{definition}
\label{modifyagentatoneplace}
    If $\pi$ is an agent, $h_0\in(\mathcal E\mathcal A)^*\mathcal E$,
    and $m$ is a probability distribution on $\mathcal A$,
    we write $\pi^{h_0\mapsto m}$ for the function which is identical to $\pi$
    except that $m$ decides the action distribution for
    $h_0$, that is,
    \[
        \pi^{h_0\mapsto m}(y|h)
        =
        \begin{cases}
            \pi(y|h) &\mbox{if $h\not=h_0$,}\\
            m(y) &\mbox{if $h=h_0$.}
        \end{cases}
    \]
\end{definition}

\begin{lemma}
    $\pi^{h_0\mapsto m}$ (as in Definition \ref{modifyagentatoneplace})
    is an agent.
\end{lemma}

\begin{proof}
    Trivial.
\end{proof}

\begin{definition}
\label{sumofdistros}
    Suppose $\vec m=(m_1,\ldots,m_n)$ are probability distributions on $\mathcal A$
    and $\vec w=(w_1,\ldots,w_n)$ are positive reals with
    $w_1+\cdots+w_n=1$. By $\vec w\cdot\vec m$ we mean the function
    on $\mathcal A$ defined by
    \[
        (\vec w\cdot\vec m)(y) = w_1m_1(y) + \cdots + w_nm_n(y).
    \]
\end{definition}

\begin{lemma}
\label{wcdotmisaprobabilitydistro}
    If $\vec m$, $\vec w$ are as in Definition \ref{sumofdistros}
    then $\vec w\cdot\vec m$ is a probability distribution on $\mathcal A$.
\end{lemma}

\begin{proof}
    See Appendix.
\end{proof}

\begin{definition}
    For any agent $\pi$, for any $h\in(\mathcal E\mathcal A)^*\mathcal E$,
    for any probability distributions $\vec m=(m_1,\ldots,m_n)$ on $\mathcal A$,
    let $\pi^{h\mapsto \vec m}=(\pi^{h\mapsto m_1},\ldots,\pi^{h\mapsto m_n})$.
\end{definition}

The following proposition shows that
for any particular history $h$ and agent $\pi$,
for any decomposition of $\pi(\cdot|h)$ into a weighted sum
of probability distributions $m_1,\ldots,m_n$,
$\pi$ has the same intelligence as the weighted mixture of the corresponding $n$ agents
$\pi^{h\mapsto \vec m}$.

\begin{proposition}
\label{longproposition}
    Let $\Upsilon$ be any weighted intelligence measure, let $\pi$ be any agent,
    and let $h\in(\mathcal E\mathcal A)^*\mathcal E$.
    Suppose $\vec m$ and $\vec w$ are as in Definition \ref{sumofdistros}.
    If $\vec w\cdot\vec m = \pi(\cdot|h)$, then
    $
        \Upsilon(\pi)
        =
        \Upsilon(\vec w\cdot \pi^{h\mapsto \vec m}).
    $
\end{proposition}

\begin{proof}
    See Appendix.
\end{proof}

\begin{definition}
    Suppose $\pi$ and $\pi_1,\ldots,\pi_n$ are agents and $\Upsilon$ is a
    weighted intelligence measure. We say that $\pi$ is \emph{strictly better than}
    $\pi_1,\ldots,\pi_n$ (as measured by $\Upsilon$) if either:
    \begin{enumerate}
        \item $\Upsilon(\pi)\geq \Upsilon(\pi_i)$ for each $i=1,\ldots,n$; or
        \item $\Upsilon(\pi)>\Upsilon(\pi_i)$ for some $i=1,\ldots,n$.
    \end{enumerate}
    We define \emph{strictly worse} similarly (change $\geq$ to $\leq$,
    $>$ to $<$).
\end{definition}

\begin{proposition}
\label{pointwisegenericnessthm}
    Let $\Upsilon$ be any weighted intelligence measure and let
    $\pi$ be an agent.
    Let $h\in (\mathcal E\mathcal A)^*\mathcal E$.
    For any probability distributions $\vec m=(m_1,\ldots,m_n)$ on $\mathcal A$,
    for any positive reals $\vec w=(w_1,\ldots,w_n)$ with $w_1+\cdots+w_n=1$,
    if $\vec w\cdot\vec m=\pi(\cdot|h)$,
    then $\pi$ is not strictly better (nor strictly worse) than
    $\pi^{h\mapsto m_1},\ldots,\pi^{h\mapsto m_n}$
    (as measured by $\Upsilon$).
\end{proposition}

\begin{proof}
    If $\pi$ is strictly better than $\pi^{h\mapsto m_1},\ldots,\pi^{h\mapsto m_n}$
    (as measured by $\Upsilon$), then this implies
    \begin{align*}
        \Upsilon(\pi)
            &= \Upsilon(\vec w\cdot\pi^{h\mapsto\vec m})
                &\mbox{(Proposition \ref{longproposition})}\\
            &= \vec w\cdot\Upsilon(\pi^{h\mapsto\vec m})
                &\mbox{(Theorem \ref{maintheorem})}\\
            &< w_1\Upsilon(\pi)+\cdots+w_n\Upsilon(\pi)
                &\mbox{(Assumption)}\\
            &= \Upsilon(\pi),
                &\mbox{($w_1+\cdots+w_n=1$)}
    \end{align*}
    absurd. Similar reasoning holds for ``strictly worse''.
\end{proof}

\begin{definition}
    (Local intelligence extrema)
    \begin{enumerate}
    \item
        We make the space of all agents into a metric space by defining
        the distance from agent $\pi$
        to agent $\rho$ to be
        $
            d(\pi,\rho)
            =
            \sup_{h\in(\mathcal E\mathcal A)^*\mathcal E,y\in\mathcal A}\left|
                \pi(y|h) - \rho(y|h)
            \right|.
        $
    \item
        Suppose $\Upsilon$ is a weighted intelligence measure. An agent $\pi$
        is a \emph{strict local maximum} (resp.\ \emph{strict local minimum})
        of $\Upsilon$ if there is some real $\epsilon>0$
        such that for every agent $\rho\not\equiv\pi$
        (recall Definition \ref{equivdefn}), if $d(\rho,\pi)<\epsilon$
        then $\Upsilon(\pi)>\Upsilon(\rho)$ (resp.\ $\Upsilon(\pi)<\Upsilon(\rho)$).
        If $\pi$ is a strict local maximum or minimum of $\Upsilon$ then
        $\pi$ is a \emph{strict local extremum} of $\Upsilon$.
    \end{enumerate}
\end{definition}

\begin{definition}
\label{deterministicinpracticedefn}
    An agent $\pi$ is \emph{deterministic in all possible histories}
    if the following condition
    holds. For all $h\in(\mathcal E\mathcal A)^*\mathcal E$,
    if $P^\pi(h)\not=0$ then for all $y\in\mathcal A$,
    $\pi(y|h)\in\{0,1\}$.
\end{definition}

Note that an agent $\pi$ can be deterministic in all possible histories
(Definition \ref{deterministicinpracticedefn}) and still assign a
probability $0<\pi(y|h)<1$, provided $P^\pi(h)=0$ (recall Remark \ref{impossibleremark}).
It is easy to show that $\pi$ is deterministic in all possible histories iff $\pi\equiv\rho$
for some strictly
deterministic $\rho$ (i.e., some $\rho$ such that $\rho(y|h)\in\{0,1\}$ for
all $y,h$).

Theorem \ref{extremitythm} below sheds light on the geometry of RL agent intelligence.
By considering agent $\pi$'s coordinates to be
the values $\pi(y|h)$
for all $y$, $h$, we can view agents as inhabiting
infinite-dimensional Euclidean space.
An agent $\pi$ is a \emph{lattice point} (i.e., a point with integer coordinates)
iff $\pi$ is strictly deterministic.
We can picture $z=\Upsilon(\pi)$ as a ``surface'' above
agents-space
(more precisely: a surface above agent-space in some places,
below it in others, and which intersects it in the ``$z$-intercept''
$\Upsilon(\pi)=0$).
Theorem \ref{extremitythm} says that, modulo $\equiv$,
$z=\Upsilon(\pi)$
cannot have any ``hyperridges'' or ``hypertroughs'' above non-lattice points.

\begin{theorem}
\label{extremitythm}
    (``Strict local extrema are deterministic'')
    For any weighted intelligence measure $\Upsilon$, for any agent $\pi$,
    if $\pi$ is a strict local extremum of $\Upsilon$, then
    $\pi$ is deterministic in all possible histories.
\end{theorem}

\begin{proof}
    Assume $\pi$ is not deterministic in all possible histories, so there exist
    $h\in(\mathcal E\mathcal A)^*\mathcal E$ and $y_0\in\mathcal A$
    such that $P^\pi(h)\not=0$ and $0<\pi(y_0|h)<1$.
    We will show $\pi$ is not a strict local maximum (a similar argument
    shows $\pi$ is not a strict local minimum) of $\Upsilon$.
    Since $0<\pi(y_0|h)<1$ and $\pi(\cdot|h)\in\Delta\mathcal A$,
    there must be some $y_1\in\mathcal A$, $y_1\not=y_0$, such that
    $0<\pi(y_1|h)<1$. Let $\epsilon>0$.
    Since $0<\pi(y_0|h)<1$ and $0<\pi(y_1|h)<1$, it follows
    that there is some $0<\epsilon'\leq \epsilon$
    such that $0<\pi(y_0|h)\pm\epsilon'<1$ and $0<\pi(y_1|h)\pm\epsilon'<1$.
    Define $m_1,m_2:\mathcal A\to \mathbb R$ by
    \[
        m_i(y) = \begin{cases}
            \pi(y|h)+(-1)^i\epsilon' &\mbox{if $y=y_0$,}\\
            \pi(y|h)-(-1)^i\epsilon' &\mbox{if $y=y_1$,}\\
            \pi(y|h) &\mbox{otherwise.}
        \end{cases}
    \]
    By choice of $\epsilon'$ it follows that $m_1,m_2\in\Delta\mathcal A$.
    Let $\vec w=(\frac12,\frac12)$, $\vec m=(m_1,m_2)$.
    Clearly $\vec w\cdot\vec m=\pi(\cdot|h)$.
    By Proposition \ref{pointwisegenericnessthm},
    $\pi$ is not strictly better than $\pi^{h\mapsto m_1},\pi^{h\mapsto m_2}$
    (as measured by $\Upsilon$).
    Thus $\Upsilon(\pi)\leq \Upsilon(\pi^{h\mapsto m_i})$
    for some $i\in\{1,2\}$.
    Clearly $\pi\not\equiv \pi^{h\mapsto m_i}$
    and $d(\pi,\pi^{h\mapsto m_i})=\epsilon'\leq\epsilon$.
    By arbitrariness of $\epsilon$, this shows
    $\pi$ is not a strict local maximum of $\Upsilon$.
\end{proof}

\section{Environment mixtures and universal environments}

\begin{definition}
\label{wprimedefn}
    An environment $\mu$ is \emph{strongly well-behaved} if $\mu$ is well-behaved
    (Definition \ref{wellbehaveddefn}) and the following condition holds.
    For every agent $\pi$, for every $t\in\mathbb N$,
    $-1\leq V^\pi_{\mu,t}\leq 1$. We write $S$ for the set of all
    strongly well-behaved environments.
\end{definition}

\begin{definition}
\label{swbperformanceaveragerdefn}
    (Compare Definition \ref{performanceaveragerdefn})
    By a \emph{$S$-restricted weighted intelligence measure},
    we mean a function
    $
        \Upsilon:
        (\Delta\mathcal A)^{(\mathcal E\mathcal A)^*\mathcal E}
        \to
        \mathbb R
    $
    (where
    $(\Delta\mathcal A)^{(\mathcal E\mathcal A)^*\mathcal E}$ denotes the set of all agents)
    such that there exists a function $w:S\to (0,\infty)$ such that:
    \begin{enumerate}
        \item
        $\sum_{\mu\in S}w(\mu)=1$.
        \item
        For every agent $\pi$, $\Upsilon(\pi)=\sum_{\mu\in S}w(\mu) V^\pi_\mu$.
    \end{enumerate}
\end{definition}

Thus, a $S$-restricted weighted intelligence measure is
a weighted intelligence measure (Definition \ref{performanceaveragerdefn})
which assigns positive weight to every strongly well-behaved environment,
zero weight to every well-behaved but not strongly well-behaved environment,
and whose weights by themselves sum up to $1$.

\begin{definition}
\label{infinitedimensionalvectorizationdefn}
    (Compare Definition \ref{vectorizationdefn})
    Let $w:S\to(0,\infty)$ be as in Definition \ref{swbperformanceaveragerdefn}.
    Suppose $\pi$ is an environment, $h\in\mathcal H$, $t\in\mathbb N$,
    and $\Upsilon$ is a $S$-restricted weighted intelligence measure. We define:
    \begin{itemize}
        \item
            $P_{S}(h):S\to [0,1]$ is the function
            $P_{S}(h)(\mu)=P_\mu(h)$ for all $\mu\in S$.
        \item
            $P^\pi_{S}(h):S\to [0,1]$ is the function
            $P^\pi_{S}(h)(\mu)=P^\pi_\mu(h)$ for all $\mu\in S$.
        \item
            $V^\pi_{S,t}(h):S\to [0,1]$ is the function
            $V^\pi_{S,t}(h)(\mu)=V^\pi_{\mu,t}(h)$ for all $\mu\in S$.
        \item
            $V^\pi_{S}(h):S\to [0,1]$ is the function
            $V^\pi_{S}(h)(\mu)=V^\pi_\mu(h)$ for all $\mu\in S$.
    \end{itemize}
\end{definition}

\begin{definition}
\label{infinitedimdotproductdefn}
    (Infinite dimensional dot product---compare Definition \ref{dotproductdefn})
    Let $w:S\to(0,\infty)$ be as in Definition \ref{swbperformanceaveragerdefn}.
    For any function $v:S\to[0,1]$,
    we define $w\cdot v=\sum_{\mu\in S}w(\mu)v(\mu)$.
\end{definition}

\begin{lemma}
    For all $w,v$ as in Definition \ref{infinitedimdotproductdefn},
    $w\cdot v$ converges (and its value does not depend on the order in which
    the summands are added).
\end{lemma}

\begin{proof}
    By condition 1 of Definition \ref{swbperformanceaveragerdefn},
    $\sum_{\mu\in S}w(\mu)=1$.
    Since $w$ has codomain $(0,\infty)$, each $|w(\mu)|=w(\mu)$,
    thus $\sum_{\mu\in S}w(\mu)$
    is absolutely convergent.
    Since $v$ has codomain $[0,1]$, it follows that
    $\sum_{\mu\in S}w(\mu)v(\mu)$ is absolutely convergent.
    By a well-known theorem from calculus, the sum of an absolutely
    convergent series does not depend on the order of summation.
\end{proof}

\begin{definition}
\label{mixtureenvdefn}
    (Mixture environments---compare Definition \ref{maindefn})
    Let $w:S\to(0,\infty)$ be as in Definition \ref{swbperformanceaveragerdefn}.
    We define $w\cdot S:(\mathcal E\mathcal A)^*\to\Delta\mathcal E$ as follows:
    for all $h\in (\mathcal E\mathcal A)^*$, $x\in\mathcal E$, let
    \[
        (w\cdot S)(x|h)
        =
        \begin{cases}
            \dfrac{w\cdot P_{S}(hx)}{w\cdot P_{S}(h)}
            &\mbox{if $w\cdot P_{S}(h)\not=0$,}\\
            1/|\mathcal E| &\mbox{otherwise.}
        \end{cases}
    \]
\end{definition}

\begin{lemma}
\label{wcdotSisenvlemma}
    (Compare Lemma \ref{mixturereallyisanagent})
    If $w:S\to(0,\infty)$ is as in Definition \ref{swbperformanceaveragerdefn},
    then $w\cdot S$ is an environment.
\end{lemma}

\begin{proof}
    See Appendix.
\end{proof}

In order to prove the Lemma \ref{envmaintheorem} below, we will need to invoke
Tannery's Theorem, a classical result from real analysis. We state the theorem
without proof.

\begin{lemma}
\label{tannerysthm}
    (Tannery's Theorem)
    Suppose $\{a_k:\mathbb N\to\mathbb R\}_{k=0}^\infty$ is a sequence of sequences
    such that for each $k$, $\lim_{t\to\infty}a_k(t)$ converges.
    Assume there is a sequence $\{M_k\in (0,\infty)\}_{k=0}^\infty$
    such that $\sum_{k=0}^\infty M_k<\infty$ and such that for all $k,t\in\mathbb N$,
    $|a_k(t)|\leq M_k$. Then
    \[
        \lim_{t\to\infty}\sum_{k=0}^\infty a_k(t)
        =
        \sum_{k=0}^\infty\lim_{t\to\infty} a_k(t).
    \]
\end{lemma}

\begin{lemma}
\label{envmaintheorem}
    (Compare Theorem \ref{maintheorem})
    Suppose $w:S\to(0,\infty)$ is as in Definition \ref{swbperformanceaveragerdefn}.
    Let $\pi$ be any agent. Then:
    \begin{enumerate}
        \item
        For any $h\in\mathcal H$,
        $P_{w\cdot S}(h)=w\cdot P_{S}(h)$.
        \item
        For any $h\in\mathcal H$,
        $P^\pi_{w\cdot S}(h)=w\cdot P^\pi_{S}(h)$.
        \item
        For any $t\in\mathbb N$,
        $V^\pi_{w\cdot S,t}=w\cdot V^\pi_{S,t}$.
        \item
        $V^\pi_{w\cdot S}=w\cdot V^\pi_{S}$.
    \end{enumerate}
\end{lemma}

\begin{proof}
    (1--3) See Appendix.

    (4) Let $\{\mu_0,\mu_1,\ldots\}$ enumerate $S$ ($S$ is countable since
    only countably many environments are Turing computable). Compute:
    \begin{align*}
        V^\pi_{w\cdot S}
            &= \lim_{t\to\infty} V^\pi_{w\cdot S,t}
                &\mbox{(Definition \ref{performancedefn})}\\
            &= \lim_{t\to\infty} w\cdot V^\pi_{S,t}
                &\mbox{(By (3))}\\
            &= \lim_{t\to\infty} \sum_{\mu\in S}w(\mu)V^\pi_{\mu,t}
                &\mbox{(Definition \ref{infinitedimdotproductdefn})}\\
            &= \lim_{t\to\infty} \sum_{k=0}^\infty w(\mu_k)V^\pi_{\mu_k,t}.
    \end{align*}
    For each $k\in\mathbb N$, define $M_k\in\mathbb R$ and $a_k:\mathbb N\to\mathbb R$
    by $M_k=w(\mu_k)$, $a_k(t)=w(\mu_k)V^\pi_{\mu_k,t}$.
    By Definition \ref{wprimedefn}, each $\mu_k\in S$ is strongly well-behaved,
    thus for each $k$, $-1\leq V^\pi_{\mu_k,t}\leq 1$.
    It follows that for all $t,k\in\mathbb N$, $|a_k(t)|\leq M_k$.
    Furthermore, $\sum_{k=0}^\infty M_k=\sum_{k=0}^\infty w(\mu_k)=1<\infty$
    by Definition \ref{swbperformanceaveragerdefn}.
    By Tannery's Theorem (Lemma \ref{tannerysthm}),
    \begin{align*}
        &{} \lim_{t\to\infty} \sum_{k=0}^\infty w(\mu_k)V^\pi_{\mu_k,t}\\
            &= \sum_{k=0}^\infty\lim_{t\to\infty} w(\mu_k)V^\pi_{\mu_k,t}
                &\mbox{(Choice of $\{\mu_k\}_{k=0}^\infty$)}\\
            &= \sum_{k=0}^\infty w(\mu_k)\lim_{t\to\infty} V^\pi_{\mu_k,t}
                &\mbox{(Algebra)}\\
            &= \sum_{k=0}^\infty w(\mu_k)V^\pi_{\mu_k}
                &\mbox{(Definition \ref{performancedefn})}\\
            &= \sum_{\mu\in S} w(\mu)V^\pi_{\mu}
                &\mbox{(Choice of $\{\mu_k\}_{k=0}^\infty$)}\\
            &= w\cdot V^\pi_{S}.
                &\mbox{(Definition \ref{infinitedimdotproductdefn})}
    \end{align*}
    So $V^\pi_{w\cdot S}=w\cdot V^\pi_{S}$.
\end{proof}

\begin{theorem}
    For any $S$-restricted weighted intelligence measure $\Upsilon$,
    there exists an environment $\mu_\Upsilon$ such that for every agent $\pi$,
    $\Upsilon(\pi)=V^\pi_{\mu_\Upsilon}$.
\end{theorem}

\begin{proof}
    Given $\Upsilon$, there is a corresponding $w:S\to(0,\infty)$ as in
    Definition \ref{swbperformanceaveragerdefn}.
    Let $\mu_\Upsilon=w\cdot S$, we claim for every agent $\pi$,
    $\Upsilon(\pi)=V^\pi_{\mu_\Upsilon}$. Let $\pi$ be any agent. Then
    \begin{align*}
        V^\pi_{\mu_\Upsilon}
            &= V^\pi_{w\cdot S}\\
            &= w\cdot V^\pi_{S}
                &\mbox{(Lemma \ref{envmaintheorem})}\\
            &= \sum_{\mu\in S}w(\mu)V^\pi_\mu
                &\mbox{(Definition \ref{infinitedimdotproductdefn})}\\
            &= \Upsilon(\pi),
                &\mbox{(By choice of $w$)}
    \end{align*}
    as desired.
\end{proof}

\section{Conclusion and future work}

\bibliographystyle{apalike} % AISTATS
\bibliography{main}

%\appendix
%
%\section{My Proof of Theorem 1}
%
%This is a boring technical proof. ( Copied from template )
%
%\section{My Proof of Theorem 2}
%
%This is a complete version of a proof sketched in the main text.
%( Copied from template )
%
% Alternative proofs of the same theorem can be added here as a few previous COLT papers did this.

\pagebreak

\onecolumn

\section*{Appendix}

\begin{proof}[Proof of Lemma \ref{factorizationlemma}]
    By induction on $h$.

    Case 1: $h=\varepsilon$. Then the lemma is trivial.

    Case 2: $h=gx$ for some $x\in\mathcal E$.
        Then
        \begin{align*}
            P^\pi_\mu(h)
                &= P^\pi_\mu(g)\mu(x|g)
                    &\mbox{(Definition \ref{pullbackdef})}\\
                &= P^\pi(g)P_\mu(g)\mu(x|g)
                    &\mbox{(Induction)}\\
                &= P^\pi(h)P_\mu(g)\mu(x|g)
                    &\mbox{(Definition \ref{pullbackdef})}\\
                &= P^\pi(h)P_\mu(h).
                    &\mbox{(Definition \ref{pullbackdef})}
        \end{align*}

    Case 3: $h=gy$ for some $y\in\mathcal A$.
        Similar to Case 2.
\end{proof}

\begin{proof}[Proof of Lemma \ref{mixturereallyisanagent}]
    Let $h\in(\mathcal E\mathcal A)^*\mathcal E$.
    Clearly $(\vec w\cdot\vec\pi)(y|h)\geq 0$ for all $y\in\mathcal A$.
    It remains to show
    $\sum_{y\in\mathcal A}(\vec w\cdot\vec\pi)(y|h)=1$.

    Case 1: $\vec w\cdot {P^{\vec\pi}}(h)=0$. Then
    each $(\vec w\cdot\vec\pi)(y|h)=1/|\mathcal A|$ so the
    claim is immediate.

    Case 2: $\vec w\cdot {P^{\vec\pi}}(h)\not=0$. Then
    \begin{align*}
        &{} \sum_{y\in\mathcal A}(\vec w\cdot\vec\pi)(y|h)\\
            &= \sum_{y\in\mathcal A}
                \frac{\vec w\cdot {P^{\vec\pi}}(hy)}{\vec w\cdot {P^{\vec\pi}}(h)}
                &\mbox{(Definition \ref{maindefn})}\\
            &= \sum_{y\in\mathcal A}
                \frac
                {\vec w\cdot(P^{\pi_1}(hy),\ldots,P^{\pi_n}(hy))}
                {\vec w\cdot {P^{\vec\pi}}(h)}
                &\mbox{(Definition \ref{vectorizationdefn})}\\
            &= \sum_{y\in\mathcal A}
                \frac
                {w_1 P^{\pi_1}(h)\pi_1(y|h)+\cdots+w_n P^{\pi_n}(h)\pi_n(y|h)}
                {\vec w\cdot {P^{\vec\pi}}(h)}
                &\mbox{(Definition \ref{pullbackdef})}\\
            &= \frac{
                w_1 P^{\pi_1}(h)\left(\mbox{$\sum_{y\in\mathcal A}\pi_1(y|h)$}\right)
                +\cdots+
                w_n P^{\pi_n}(h)\left(\mbox{$\sum_{y\in\mathcal A}\pi_n(y|h)$}\right)
                }
                {\vec w\cdot {P^{\vec\pi}}(h)}
                &\mbox{(Algebra)}\\
            &= \frac
                {w_1 P^{\pi_1}(h)\cdot 1 + \cdots + w_n P^{\pi_n}(h)\cdot1}
                {\vec w\cdot {P^{\vec\pi}}(h)}
                =\frac{\vec w\cdot {P^{\vec\pi}}(h)}{\vec w\cdot {P^{\vec\pi}}(h)}=1.
                &\mbox{($\pi_i$ are agents)}
    \end{align*}
\end{proof}

\begin{proof}[Proof of Lemma \ref{piopluspilemma}]
    Recall that the real numbers satisfy the so-called \emph{null-factor law}:
    for all real numbers $a$ and $b$, if $ab=0$, then $a=0$ or $b=0$.
    In other words, the product of two nonzero real numbers can never be zero.

    Write $\vec\pi$ for $(\pi,\ldots,\pi)$.
    We prove conditions 1 and 2 of Definition \ref{equivdefn}
    simultaneously by induction on $h$.
 
    Case 1: $h=\varepsilon$. Then
    $P^\pi(h)=\vec w\cdot{P^{\vec\pi}}(h)=1\not=0$, so
    vacuously $P^\pi(h)=0$ iff $\vec w\cdot{P^{\vec\pi}}(h)=0$
    (proving condition 1).
    For condition 2, there is nothing to check, since
    $\varepsilon\not\in(\mathcal E\mathcal A)^*\mathcal E$.

    Case 2: $h=h_0y_0$ for some
        $h_0\in(\mathcal E\mathcal A)^*\mathcal E$, $y_0\in\mathcal A$.
        For condition 2, there is nothing to prove, since
        $h\not\in(\mathcal E\mathcal A)^*\mathcal E$.
        For condition 1, we consider two cases.

        Subcase 2.1: $P^\pi(h_0)=0$.
        By induction, condition 1 holds for $h_0$, so
        $\vec w\cdot{P^{\vec\pi}}(h_0)=0$.
        By Definition \ref{pullbackdef},
        $P^\pi(h)=P^\pi(h_0)\pi(y_0|h_0)=0$
        and $P^{\vec w\cdot\vec\pi}(h)=0(\vec w\cdot\vec\pi)(y_0|h_0)=0$.
        So $P^\pi(h)=0$ iff $P^{\vec w\cdot\vec\pi}(h)=0$.

        Subcase 2.2: $P^\pi(h_0)\not=0$.
        Then
        \begin{align*}
            P^{\vec w\cdot \vec\pi}(h)
                &= \vec w\cdot{P^{\vec\pi}}(h)
                    &\mbox{(Theorem \ref{maintheorem})}\\
                &= w_1 P^\pi(h)+\cdots+w_n P^\pi(h)
                    &\mbox{(Def.\ of $\vec w$ and $\vec\pi$)}\\
                &= P^\pi(h)
                    &\mbox{($w_1+\cdots+w_n=1$)}\\
                &= P^\pi(h_0)\pi(y_0|h_0).
                    &\mbox{(Definition \ref{pullbackdef})}
        \end{align*}
        Since $P^\pi(h_0)\not=0$,
        by the null-factor law,
        it follows that
        $P^{\vec w\cdot\vec\pi}(h)=0$ iff $P^\pi(h)=0$ iff $\pi(y_0|h_0)=0$.

    Case 3: $h=h_0x$ for some $h_0\in (\mathcal E\mathcal A)^*$,
        $x\in\mathcal E$.
        By induction, conditions 1 and 2 hold for $h_0$.
        By Definition \ref{pullbackdef},
        $P^\pi(h)=P^\pi(h_0)$ and
        $P^{\vec w\cdot\vec\pi}(h)=P^{\vec w\cdot\vec\pi}(h_0)$,
        so condition 1 for $h$ follows.

        For condition 2,
        assume $P^\pi(h)\not=0$ and let $y\in\mathcal A$.
        By choice of $\vec w$ and $\vec\pi$,
        $\vec w\cdot{P^{\vec\pi}}(h)=w_1P^\pi(h)+\cdots+w_nP^\pi(h)=P^\pi(h)$.
        So, since $P^\pi(h)\not=0$, $\vec w\cdot{P^{\vec\pi}}(h)\not=0$.
        Thus
        \begin{align*}
            (\vec w\cdot\vec\pi)(y|h)
                &= \frac{\vec w\cdot {P^{\vec\pi}}(hy)}{\vec w\cdot{P^{\vec\pi}}(h)}
                    &\mbox{(Definition \ref{maindefn})}\\
                &= \frac{w_1P^\pi(hy)+\cdots+w_nP^\pi(hy)}
                    {w_1P^\pi(h)+\cdots+w_nP^\pi(h)}
                    &\mbox{(Def.\ of $\vec w$ and $\vec\pi$)}\\
                &= \frac{w_1P^\pi(h)+\cdots+w_nP^\pi(h)}{w_1P^\pi(h)+\cdots+w_nP^\pi(h)}
                    \pi(y|h)
                    &\mbox{(Definition \ref{pullbackdef})}\\
                &= \pi(y|h).
        \end{align*}
\end{proof}

\begin{proof}[Proof of Lemma \ref{reflectionmakesjanuslemma}]
    Let $\vec w=(\frac12,\frac12)$.
    For any $h\in(\mathcal E\mathcal A)^*\mathcal E$ and $y\in\mathcal A$,
    we claim
    \[
        \overline{\vec w\cdot(\pi,\overline{\pi})}(y|h)
        =(\vec w\cdot(\pi,\overline{\pi}))(y|h).
    \]
    Noting that
    $\vec w\cdot P^{(\pi,\overline{\pi})}(h)
    =\frac12P^\pi(h)+\frac12P^{\overline\pi}(h)$
    and
    $\vec w\cdot P^{(\pi,\overline{\pi})}(\overline h)
    =\frac12P^\pi(\overline h)+\frac12P^{\overline\pi}(\overline h)$,
    Lemmas \ref{doublenegationlemma} and \ref{asteriskcommuteswithoverlinelemma}
    imply that
    $\vec w\cdot P^{(\pi,\overline{\pi})}(h)
    =\vec w\cdot P^{(\pi,\overline{\pi})}(\overline h)$.
    So if
    $\vec w\cdot P^{(\pi,\overline{\pi})}(\overline h)=0$
    then $\vec w\cdot P^{(\pi,\overline{\pi})}(h)=0$
    and it follows from
    Definition \ref{maindefn}
    and Lemma \ref{asteriskcommuteswithoverlinelemma} that
    $\overline{\vec w\cdot(\pi,\overline{\pi})}(y|h)
    =(\vec w\cdot(\pi,\overline{\pi}))(y|h)=1/|\mathcal A|$.
    So assume $\vec w\cdot P^{(\pi,\overline{\pi})}(\overline h)\not=0$.
    Then:
    \begin{align*}
        \overline{\vec w\cdot(\pi,\overline{\pi})}(y|h)
        &= (\vec w\cdot(\pi,\overline{\pi}))(y|\overline h)
            &\mbox{(Definition \ref{dualagentsdefn})}\\
        &= \frac
            {\frac12P^\pi(\overline hy)+\frac12P^{\overline\pi}(\overline hy)}
            {\frac12P^\pi(\overline h)+\frac12P^{\overline\pi}(\overline h)}
            &\mbox{(Definition \ref{maindefn})}\\
        &= \frac
            {\frac12P^\pi(\overline{hy})+\frac12P^{\overline\pi}(\overline{hy})}
            {\frac12P^\pi(\overline h)+\frac12P^{\overline\pi}(\overline h)}
            &\mbox{(Clearly $\overline hy=\overline{hy}$)}\\
        &= \frac
            {\frac12P^{\overline\pi}(hy)+\frac12P^{\overline{\overline\pi}}(hy)}
            {\frac12P^{\overline\pi}(h)+\frac12P^{\overline{\overline\pi}}(h)}
            &\mbox{(Lemma \ref{asteriskcommuteswithoverlinelemma})}\\
        &= (\vec w\cdot(\overline{\overline\pi},\overline\pi))(y|h)
            &\mbox{(Definition \ref{maindefn})}\\
        &= (\vec w\cdot(\pi,\overline\pi))(y|h).
            &\mbox{(Lemma \ref{doublenegationlemma})}
    \end{align*}
\end{proof}

\begin{proof}[Proof of Lemma \ref{wcdotmisaprobabilitydistro}]
    Clearly for every $y\in\mathcal A$,
    $(\vec w\cdot\vec m)(y) = w_1m_1(y) + \cdots + w_nm_n(y)$ is a nonnegative
    real. It remains to show $\sum_{y\in\mathcal A}(\vec w\cdot\vec m)(y)=1$.
    We compute:
    \begin{align*}
        &{} \sum_{y\in\mathcal A}(\vec w\cdot\vec m)(y)\\
        &=
        \sum_{y\in\mathcal A} w_1m_1(y) + \cdots + w_nm_n(y)
            &\mbox{(Definition \ref{sumofdistros})}\\
        &=
        w_1\left(\sum_{y\in\mathcal A} m_1(y)\right)
        + \cdots + w_n\left(\sum_{y\in\mathcal A}m_n(y)\right)
            &\mbox{(Basic Algebra)}\\
        &= w_1 + \cdots + w_n
            &\mbox{($m_1,\ldots,m_n$ are probability distr's)}\\
        &= 1.
    \end{align*}
\end{proof}

The following auxiliary lemmas will be used in our proof of
Proposition \ref{longproposition}.

\begin{lemma}
\label{firsttechlemmaforgenericity}
    Suppose $\pi$, $h_0$, $m$ are as in Definition \ref{modifyagentatoneplace}.
    Let $h\in\mathcal H$ be such that
    for every $y\in\mathcal A$,
    $h_0y$ is not an initial segment of $h$.
    Then $P^{\pi^{h_0\mapsto m}}(h)=P^\pi(h)$.
\end{lemma}

\begin{proof}
    By induction on $h$.
\end{proof}

\begin{lemma}
\label{thirdtechlemmaforgenericity}
    Suppose $\pi$, $h_0$, $m$ are as in Definition \ref{modifyagentatoneplace}.
    For any $y\in\mathcal A$,
    $P^{\pi^{h_0\mapsto m}}(h_0y)=P^\pi(h_0)m(y)$.
\end{lemma}

\begin{proof}
    Immediate by Definition \ref{pullbackdef} and Lemma \ref{firsttechlemmaforgenericity}.
\end{proof}

\begin{lemma}
\label{secondtechlemmaforgenericity}
    Suppose $\pi$, $h_0$, $m$ are as in Definition \ref{modifyagentatoneplace}.
    Assume $h\in\mathcal H$, $y_0\in\mathcal A$, and $h_0y_0$ is
    an initial segment of $h$. Assume $\pi(y_0|h_0)\not=0$. Then
    $P^{\pi^{h_0\mapsto m}}(h) = \frac{P^\pi(h)m(y_0)}{\pi(y_0|h_0)}$.
\end{lemma}

\begin{proof}
    By induction on $h$.

    Case 1: $h=h_0y_0$. Then
    \begin{align*}
        P^{\pi^{h_0\mapsto m}}(h)
        &= P^{\pi^{h_0\mapsto m}}(h_0)\pi^{h_0\mapsto m}(y_0|h_0)
            &\mbox{(Definition \ref{pullbackdef})}\\
        &= P^\pi(h_0)\pi^{h_0\mapsto m}(y_0|h_0)
            &\mbox{(Lemma \ref{firsttechlemmaforgenericity})}\\
        &= P^\pi(h_0)m(y_0)
            &\mbox{(Definition \ref{modifyagentatoneplace})}\\
        &= \frac{P^\pi(h_0)\pi(y_0|h_0)m(y_0)}{\pi(y_0|h_0)}
            &\mbox{(Basic Algebra)}\\
        &= \frac{P^\pi(h)m(y_0)}{\pi(y_0|h_0)}.
            &\mbox{(Definition \ref{pullbackdef})}
    \end{align*}

    Case 2: $h=h_0 y_0 h_1 x$ for some $h_1\in\mathcal H$
        and $x\in\mathcal E$. Then
    \begin{align*}
        P^{\pi^{h_0\mapsto m}}(h)
        &= P^{\pi^{h_0\mapsto m}}(h_0 y_0 h_1)
            &\mbox{(Definition \ref{pullbackdef})}\\
        &= \frac{P^\pi(h_0 y_0 h_1)m(y_0)}{\pi(y_0|h_0)}
            &\mbox{(Induction)}\\
        &= \frac{P^\pi(h_0 a_0 h_1 x)m(y_0)}{\pi(y_0|h_0)}
            &\mbox{(Definition \ref{pullbackdef})}\\
        &= \frac{P^\pi(h)m(y_0)}{\pi(y_0|h_0)}.
    \end{align*}

    Case 3: $h=h_0 y_0 h_1 y$ for some $h_1\in\mathcal H$ and
        $y\in\mathcal A$. Then
    \begin{align*}
        P^{\pi^{h_0\mapsto m}}(h)
        &= P^{\pi^{h_0\mapsto m}}(h_0 y_0 h_1)
            \pi^{h_0\mapsto m}(y|h_0 y_0 h_1)
            &\mbox{(Definition \ref{pullbackdef})}\\
        &= P^{\pi^{h_0\mapsto m}}(h_0 y_0 h_1)
            \pi(y|h_0 a h_1)
            &\mbox{(Definition \ref{modifyagentatoneplace})}\\
        &= \frac{P^\pi(h_0 y_0 h_1)\pi(y|h_0 y_0 h_1)m(y_0)}{\pi(y_0|h_0)}
            &\mbox{(Induction)}\\
        &= \frac{P^\pi(h_0 y_0 h_1 y)m(y_0)}{\pi(y_0|h_0)}
            &\mbox{(Definition \ref{pullbackdef})}\\
        &= \frac{P^\pi(h)m(y_0)}{\pi(y_0|h_0)}.
    \end{align*}
\end{proof}

\begin{proof}[Proof of Proposition \ref{longproposition}]
    \textbf{Subclaim:}For every $g\in\mathcal H$,
    $P^\pi(g)=P^{\vec w\cdot\pi^{h\mapsto \vec m}}(g)$.
    We prove this by induction on $g$.

    Case 1: $g=\varepsilon$.
    Then $P^\pi(g)=1
    =P^{\vec w\cdot\pi^{h\mapsto \vec m}}(g)$.

    Case 2: $g=fx$ for some $x\in\mathcal E$.
    Then
    \begin{align*}
        P^\pi(g)
            &= P^\pi(f)
                &\mbox{(Definition \ref{pullbackdef})}\\
            &= P^{\vec w\cdot\pi^{h\mapsto \vec m}}(f)
                &\mbox{(Induction)}\\
            &= P^{\vec w\cdot\pi^{h\mapsto \vec m}}(g).
                &\mbox{(Definition \ref{pullbackdef})}
    \end{align*}

    Case 3: $g=fy$ for some $y\in\mathcal A$.

    Subcase 3.1: $P^\pi(f)=0$.
    Then
    \begin{align*}
        P^{\vec w\cdot\pi^{h\mapsto \vec m}}(g)
            &= P^{\vec w\cdot\pi^{h\mapsto \vec m}}(f)
            (\vec w\cdot\pi^{h\mapsto \vec m})(y|f)
                &\mbox{(Definition \ref{pullbackdef})}\\
            &= P^\pi(f)(\vec w\cdot\pi^{h\mapsto \vec m})(y|f)
                &\mbox{(Induction)}\\
            &= 0.
    \end{align*}
    Similarly, $P^\pi(g)=0$. So $P^{\vec w\cdot\pi^{h\mapsto \vec m}}(g)=P^\pi(g)$.

    Subcase 3.2: $P^\pi(f)\not=0$ and $f=h$. Then:
    \begin{align*}
        P^{\vec w\cdot\pi^{h\mapsto \vec m}}(g)
            &= P^{\vec w\cdot\pi^{h\mapsto \vec m}}(hy)\\
            &= \vec w\cdot{P^{\pi^{h\mapsto \vec m}}}(hy)
                    &\mbox{(Theorem \ref{maintheorem})}\\
            &= w_1P^\pi(h)m_1(y)+\cdots+w_nP^\pi(h)m_n(y)
                    &\mbox{(Lemma \ref{thirdtechlemmaforgenericity})}\\
            &= P^\pi(h)\pi(y|h)
                    &\mbox{($\vec w\cdot\vec m=\pi(\cdot|h)$)}\\
            &= P^\pi(hy) = P^\pi(g).
                    &\mbox{(Definition \ref{pullbackdef})}
    \end{align*}

    Subcase 3.3: $P^\pi(f)\not=0$, $f\not=h$, and
    $f$ has an initial segment $h y_0$ ($y_0\in\mathcal A$).

    Then $\pi(y_0|h)\not=0$, lest
    we would have $P^\pi(f)=0$. Thus:
    \begin{align*}
        P^{\vec w\cdot\pi^{h\mapsto \vec m}}(g)
            &= P^{\vec w\cdot \pi^{h\mapsto \vec m}}(fy)\\
            &= \vec w\cdot{P^{\pi^{h\mapsto \vec m}}}(fy)
                    &\mbox{(Theorem \ref{maintheorem})}\\
            &= w_1\frac{P^\pi(fy)m_1(y_0)}{\pi(y_0|h)}
                +\cdots+w_n\frac{P^\pi(fy)m_n(y_0)}{\pi(y_0|h)}
                    &\mbox{(Lemma \ref{secondtechlemmaforgenericity})}\\
            &= \frac{P^\pi(fy)}{\pi(y_0|h)}(w_1m_1(y_0)+\cdots+w_nm_n(y_0))
                    &\mbox{(Basic Algebra)}\\
            &= \frac{P^\pi(fy)}{\pi(y_0|h)}\pi(y_0|h)
                    &\mbox{($\vec w\cdot\vec m=\pi(\cdot|h)$)}\\
            &= P^\pi(fy) = P^\pi(g).
    \end{align*}

    Subcase 3.4: $P^\pi(f)\not=0$, $f\not=h$, and $f$ has no initial segment
        of the form $hy_0$. Then:
    \begin{align*}
        P^{\vec w\cdot\pi^{h\mapsto \vec m}}(g)
            &= P^{\vec w\cdot\pi^{h\mapsto \vec m}}(fy)\\
            &= \vec w\cdot{P^{\pi^{h\mapsto \vec m}}}(fy)
                    &\mbox{(Theorem \ref{maintheorem})}\\
            &= w_1P^\pi(fy)+\cdots+w_nP^\pi(fy)
                    &\mbox{(Lemma \ref{firsttechlemmaforgenericity})}\\
            &= P^\pi(fy) = P^\pi(g),
                    &\mbox{($w_1+\cdots+w_n=1$)}
    \end{align*}
    as desired.

    This finishes the proof of the Subclaim.
    By Lemma \ref{factorizationlemma}, the Subclaim implies
    that for every well-behaved $\mu$ and every $g\in\mathcal H$,
    $
    P^\pi_\mu(g)
    =
    P^{\vec w\cdot\pi^{h\mapsto \vec m}}_\mu(g)
    $.
    By Definition \ref{performancedefn} (part 1), this implies that
    for every well-behaved $\mu$ and every $t\in\mathbb N$,
    $
        V^{\pi}_{\mu,t}
        =
        V^{\vec w\cdot \pi^{h\mapsto \vec m}}_{\mu,t}.
    $
    The proposition follows by Definition \ref{performancedefn} (part 2).
\end{proof}

\begin{proof}[Proof of Lemma \ref{wcdotSisenvlemma}]
    Let $h\in(\mathcal E\mathcal A)^*$.
    Clearly $(w\cdot S)(x|h)\geq 0$ for all $x\in\mathcal E$.
    It remains to show $\sum_{x\in\mathcal E}(w\cdot S)(x|h)=1$.
    If $w\cdot P_{S}(h)=0$ then each $(w\cdot S)(x|h)=1/|\mathcal E|$
    so the claim is immediate; assume not. Then:
    \begin{align*}
        &{} \sum_{x\in\mathcal E}(w\cdot S)(x|h)\\
            &= \sum_{x\in\mathcal E}\frac{w\cdot P_{S}(hx)}{w\cdot P_{S}(h)}
                &\mbox{(Definition \ref{mixtureenvdefn})}\\
            &= \sum_{x\in\mathcal E}
                \frac{
                    \sum_{\mu\in S}w(\mu)P_\mu(hx)
                }{
                    \sum_{\mu\in S}w(\mu)P_\mu(h)
                }
                &\mbox{(Definition \ref{infinitedimensionalvectorizationdefn})}\\
            &= \sum_{x\in\mathcal E}
                \frac{
                    \sum_{\mu\in S}w(\mu)P_\mu(h)\mu(x|h)
                }{
                    \sum_{\mu\in S}w(\mu)P_\mu(h)
                }.
                &\mbox{(Definition \ref{pullbackdef})}
    \end{align*}
    By absolute convergence, we can rearrange the order of summation without
    altering the sum, so the above is
    \[
        \frac{
            \sum_{\mu\in S}w(\mu)P_\mu(h)\sum_{x\in\mathcal E}\mu(x|h)
        }{
            \sum_{\mu\in S}w(\mu)P_\mu(h)
        },
    \]
    and each $\sum_{x\in\mathcal E}\mu(x|h)=1$ since each $\mu\in\Delta\mathcal E$,
    so the whole fraction reduces to $1$.
\end{proof}

\begin{proof}[Proof of Lemma \ref{envmaintheorem} (1--3)]
    (1) By induction on $h$.

    Case 1: $h=\varepsilon$. Then
    \begin{align*}
        w\cdot P_{S}(h)
        &= \sum_{\mu\in S}w(\mu)P_{S}(h)(\mu)
            &\mbox{(Definition \ref{infinitedimdotproductdefn})}\\
        &= \sum_{\mu\in S}w(\mu)P_\mu(h)
            &\mbox{(Definition \ref{infinitedimensionalvectorizationdefn})}\\
        &= \sum_{\mu\in S}w(\mu)
            &\mbox{($P_\mu(\varepsilon)=1$)}\\
        &= 1
            &\mbox{(Definition \ref{swbperformanceaveragerdefn})}\\
        &= P_{w\cdot S}(h).
            &\mbox{(Definition \ref{pullbackdef})}
    \end{align*}

    Case 2: $h=gx$ for some $x\in\mathcal E$.

    Subcase 2.1: $w\cdot P_{S}(g)=0$.
        This means $\sum_{\mu\in S}w(\mu)P_\mu(g)=0$.
        Since each $w(\mu)>0$, this implies each $P_\mu(g)=0$.
        From this it easily follows that
        $P_{w\cdot S}(gx)=w\cdot P_{S}(gx)=0$.

    Subcase 2.2: $w\cdot P_{S}(g)\not=0$. Then
    \begin{align*}
        P_{w\cdot S}(h)
            &= P_{w\cdot S}(g)(w\cdot S)(x|g)
                &\mbox{(Definition \ref{pullbackdef})}\\
            &= w\cdot P_{S}(g)(w\cdot S)(x|g)
                &\mbox{(Induction)}\\
            &= w\cdot P_{S}(g)\frac{w\cdot P_{S}(gx)}{w\cdot P_{S}(g)}
                &\mbox{(Definition \ref{mixtureenvdefn})}\\
            &= w\cdot P_{S}(gx) = w\cdot P_{S}(h).
    \end{align*}

    Case 3: $h=gy$ for some $y\in\mathcal A$.
    Then
    \begin{align*}
        P_{w\cdot S}(h)
            &= P_{w\cdot S}(g)
                &\mbox{(Definition \ref{pullbackdef})}\\
            &= w\cdot P_{S}(g)
                &\mbox{(Induction)}\\
            &= \sum_{\mu\in S} w(\mu)P_\mu(g)
                &\mbox{(Definition \ref{infinitedimdotproductdefn})}\\
            &= \sum_{\mu\in S} w(\mu)P_\mu(gy)
                &\mbox{(Definition \ref{pullbackdef})}\\
            &= w\cdot P_{S}(gy) = w\cdot P_{S}(h).
                &\mbox{(Definition \ref{infinitedimdotproductdefn})}
    \end{align*}

    (2) Compute:
    \begin{align*}
        P^\pi_{w\cdot S}(h)
            &= P^\pi(h) P_{w\cdot S}(h)
                &\mbox{(Lemma \ref{factorizationlemma})}\\
            &= P^\pi(h) w\cdot P_{S}(h)
                &\mbox{(By (1))}\\
            &= P^\pi(h) \sum_{\mu\in S}w(\mu)P_\mu(h)
                &\mbox{(Definition \ref{infinitedimdotproductdefn})}\\
            &= \sum_{\mu\in S}w(\mu)P^\pi(h)P_\mu(h)
                &\mbox{(Algebra)}\\
            &= \sum_{\mu\in S}w(\mu)P^\pi_\mu(h)
                &\mbox{(Lemma \ref{factorizationlemma})}\\
            &= w\cdot P^\pi_{S}(h).
                &\mbox{(Definition \ref{infinitedimdotproductdefn})}
    \end{align*}

    (3) Let $X_t$, $R$ be as in Definition \ref{performancedefn} and compute:
    \begin{align*}
        V^\pi_{w\cdot S,t}
            &= \sum_{h\in X_t}R(h)P^\pi_{w\cdot S}(h)
                &\mbox{(Definition \ref{performancedefn})}\\
            &= \sum_{h\in X_t}R(h)w\cdot P^\pi_{S}(h)
                &\mbox{(By (2))}\\
            &= \sum_{h\in X_t}R(h)\sum_{\mu\in S}w(\mu)P^\pi_\mu(h).
                &\mbox{(Definition \ref{infinitedimdotproductdefn})}
    \end{align*}
    Since $X_t$ is finite, this sum is absolutely convergent, so we can
    rearrange terms, and the sum is equal to
    \begin{align*}
        \sum_{\mu\in S}w(\mu)\sum_{h\in X_t}R(h)P^\pi_\mu(h)
            &= \sum_{\mu\in S}w(\mu)V^\pi_{\mu,t}
                &\mbox{(Definition \ref{performancedefn})}\\
            &= w\cdot V^\pi_{S,t}.
                &\mbox{(Definition \ref{infinitedimdotproductdefn})}
    \end{align*}
\end{proof}

\end{document}
